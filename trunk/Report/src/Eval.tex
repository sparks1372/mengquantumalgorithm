\chapter{Evaluation and Future Work}
\label{sec:evalandfutwork}

\section{Have the Requirements Been Met?}

The aim of this project was to provide an easily extendible toolkit to assist research into the discovery of quantum artefacts through heuristic search.
Previous research was deemed inefficient with bespoke development of implementations to perform peripheral tasks, such as artefact and state representation, and circuit simulation, carried out by each individual researcher.
The toolkit was intended to provide a more efficient environment for such research by providing implementations of these peripheral tasks.

As described in Section \ref{sec:reqs}, the toolkit produced by this project is split into three distinct components.
The first component is a framework that aims to provide the core research environment.
It is in the form of a library that can be embedded into any third party application.
The framework provides the orchestration between implementations of the peripheral tasks and the user provided search engine, suitability measure and search problem.
The framework provides two standalone graphical applications to create and edit test suites, and to create and edit matrices used to define custom unitary operations.

The second component is a prototype that provides implementations of a genetic programming based search engine, multiple suitability measures and multiple search problems.
The search engine is based on Q-Pace IV\cite{masseythesis} and written using the Java-based Evolutionary Computation Research System ECJ\cite{ecjtool}.
A total of $10$ suitability measures are provided.
The suitability measures are from two main categories.
The first category contains all the Simple suitability measures, see Section \ref{sec:simplsuitmeas} for more details.
These only use the modulus of the complex numbers in the state vectors being compared.
The second category contains all the Phase Aware suitability measures, see Section \ref{sec:phaseawaresuitmeas} for more details.
These use both the modulus and the argument values of the complex number in the state vectors being compared.

The third component is a client application that provides the framework with a standalone graphical user interface.
The framework is not a standalone application and needs to be embedded within another application.
Without providing this client a third party application that embeds the framework would have to be produced before improved efficiency could be realised.
This client provides a number of research aids including rendered circuit visualisation, quantum state visualisation and graphical step-by-step evaluation of quantum circuits.

In Section \ref{sec:reqs}, $27$ requirements for the toolkit were specified.
Section \ref{sec:tracability} provides a way to trace the requirements into the design and implementation with reference to the tests verifying the requirements.
The traceability matrix shows that each of the $27$ requirements has been met by the design and implementation and has been verified by the testing process.

In a formal sense we should conclude that the requirements agreed have been delivered.
Now it is appropriate to take a step back and carry out a more holistic evaluation, assessing the strengths and weaknesses of the work done.

\section{Strengths of the Toolkit}

There are several strengths of the toolkit produced.
One of the main goals of the toolkit is extendibility; the design of the framework is heavily focused on this.

During the experimentation summarised in Section \ref{sec:experimentation} this flexibility was tested.
The Zero-Focused Simple suitability measure, explained in Section \ref{sec:simplsuitmeas}, was not originally developed.
During the experimentation of the Max Permutation problem, see Section \ref{sec:maxproblemexp}, the basic variants of both the Simple and Phase Sensitive suitability measures did not produce any useful results.
As a consequence the Zero-Focused Simple suitability measure was developed and added to the prototype.

The addition of this suitability measure was straight forward.
The class implementing the suitability measure was developed and the process required to add the new suitability measure to the configuration file took roughly 2 minutes.
It is a very straight forward process.

The experimentation also showed how easy it was to create and edit search problems.
During the experimentation process, both the client and standalone editors were used to perform these tasks.
Both methods were clear to use and the reuse of components made the transition between the two effortless.

\section{Areas of Improvement and Future Work}

There are areas of the framework that could be the focus of future work.

Some of the circuits produced during the experimentation phase contained sequences of gates that didn't result in any change to the state.
This is not ideal and require manual optimisation to produce a circuit with only functional gates.
There are a few rules that could be included in an higher efficiency circuit builder to reduce the redundancy of circuits built.
The provided circuit builder can perform simple improvements by removing sequences such as
$
\Qcircuit @C=1.0em @R=.7em {&\gate{H}&\gate{H}&\qw}
$.
However, the current rules are very simple and the circuit builder only has a memory of a single gate, i.e. the last added gate, so the sequence
$
\Qcircuit @C=1.0em @R=.7em {&\gate{X}&\gate{H}&\gate{H}&\gate{X}&\qw}
$
can currently only be improved to 
$
\Qcircuit @C=1.0em @R=.7em {&\gate{X}&\gate{X}&\qw}
$
which obviously isn't optimal as this sequence can also be removed.

A second addition would assist with understanding.
When constructing a circuit from an algorithm some of the instructions are ignored, see Section \ref{sec:quantumcircuits}, with the result that the algorithm contains instructions that did not contribute to the specific circuit.
I refer to these as ``inactive'' instructions.
I refer to the instructions that are not ignored as ``active'' instructions.
I use the term ``Active Algorithm'' to refer to an algorithm that only contains ``active'' instructions.
As the ``Active Algorithm'' produces the evaluated circuits only ``active'' instructions contribute to the proffered solution.
For a researcher, understanding the ``Active Algorithm'' is more important than the full algorithm.
It is important to note that the ``Active Algorithm'' may be different for each system size.
The framework could easily be extended to provide this as part of the result.

A third area of future development would be an extension of the circuit optimisation rules mentioned as the first area of improvement.
Various problems have certain properties that cannot currently be expressed to the framework.
One such search problem is the quantum teleportation protocol, see Section \ref{sec:quantteleproto}.
Due to the spacial separation of the qubits held by Bob and Alice certain operations cannot be performed by the solution.
For example a controlled gate acting on Bob's qubit controlled by one of Alice's qubits has to be modelled to represent the required measurement and classical communication to communicate to Bob whether the operation should be applied.
As a result any superposition that contained the controlling qubit is effectively collapsed due to the measurement.
To model this without explicit measurement would require rules to ensure further operations cannot be applied to but can be controlled by Alice's qubit used to control the operation on Bob's qubit.

It is important to note that any rules to improve efficiency or enforce properties of individual problems should only be applied at the circuit construction phase.
Enforcing these rules at the search phase could remove vital areas of the search space.
Although certain algorithms would not meet the restrictions they could form part of the search path to a desired solution.
When enforced by the circuit builder all algorithms are valid and the rules are applied to ensure all circuits produced are also valid.
% If search engines were to enforce arbitrary user specified restrictions all search engines would have to include the restrictions.
% Whereas if it were enforced by the circuit builder the restrictions can be applied to any search engine and any update in the specification language only requires an update to framework rather than resulting in search engines that comply with different versions of the restriction specification language.

The fourth area of improvement would be the customisation of suitability measures.
Currently the search engine is able to provide customisation via either an on-screen dialog or parametrised \emph{search} method.
Through experimentation it was found that this ability to customise the search engine parameters was very useful.
However, being able to configure the suitability measures, such as whether hits were counted or component weighting, only at the source code level was quite inconvenient.
It is proposed that the suitability measures provide on-screen dialog and dedicated customisation methods.

The final improvement proposed is potentially quite complex.
The idea of saving algorithms and providing algorithm editing facilities sounds quite simple.
This could be provided by simply using the serialisation provided by Java however this would not match the use of XML throughout the rest of the framework and is potentially less compatible with third party applications.
Therefore an XML file based solution would be preferable.
However, this requires a parser to be able to interpret the specification of an arbitrary \emph{expnode} expression.
Additionally, to provide editing facilities an algorithm editor would have to be designed.
This again sounds quite simple.
However due to the potentially bloated algorithms produced by search techniques the editor assist the user with understanding an algorithm in a similar way the Step-By-Step evaluator assists the user to understand a circuit.
Step-By-Step algorithm evaluation is a possible techniques that could be incorporated.
It also could include functionality usually found in modern Integrated Development Environments such as structural folding and content assistance such as bracket matching and a dedicated \emph{expnode} expression editor.

\section{Experimentation Summary}

An advantage of producing a usable toolkit before the end of the project was that time could be dedicated to using the toolkit to solve a selection quantum problems.
The results were very encouraging.

The Deutsch and Deutsch-Jozsa experiments produced results that were particularly impressive, see Sections \ref{sec:deutschexperiment} and \ref{sec:deutschjozsaexperiment}.
The algorithms that were produced had not previously been produced by heuristic search.
Both resulted in deterministic results, the best previous heuristic search result for the Deutsch-Jozsa problem was a probabilistic circuit and the single qubit Deutsch problem had never previously been tackled by heuristic search.
These results are human competitive and previously unseen results from heuristic search.
The Quantum Fourier Transform and Max Permutation experiments were impressive but not unprecedented.

All the experiments showed one property that was particularly impressive yet a second that is quite disappointing.
The impressive property was how minimal the solutions produced were.
The circuit builder is only implemented with a very simple optimisation rule yet still the circuits produced were still very small.
However, the lack of scalability is relatively disappointing.
The main advantage of an algorithm compared to a program is the application over an arbitrary system size.

It may be that the search problems were defined with too many test cases concentrated in too few test sets.
Further experimentation would have to be performed to verify this theory.

Future work on the search engine provided in the toolkit could be undertaken to potentially address this issue.
I suggest the introduction of multiple populations.
Each population would concentrate on forming a solution for system sizes up to a value $x$.
The value $x$ would be different subpopulation.
Migration would be allowed of highly suitable individuals from a subpopulation to a second subpopulation with a higher value of $x$.
This is a similar idea to coevolution where the problem evolves alongside the original population with effectively an ``inverse'' suitability measure.
This is based on the idea that a solution for smaller system sizes can provide useful stepping stones when searching for a solution to cover larger system sizes.

In my opinion this process of effectively increasing the difficulty of the problem would in the majority of cases be more effective than attempting to solve the full problem in a single population.
This opinion is based on my theory that this subpopulation idea would effectively use the ``lower'' subpopulations to prune the search space for the ``higher'' subpopulations.
As the search space increases each time a qubit is added it would be easier to perform this pruning on the search spaces of lower system sizes.
Despite the search space increasing with system size it would already be partially pruned due to the results of ``lower'' subpopulations.

\section{Project Evaluation}

In conclusion the project as a whole has been successful.
The high level project aim was to provide a toolkit to the research community that provided implementations of tasks peripheral to research into quantum algorithms.
The toolkit produced does this.
With a code base of just under $13000$ lines of code it shows the level of development that is no longer required by each researcher.
Not only does the toolkit provide the implementations of peripheral tasks but also implements features that are likely to be useful to users that they may not have developed themselves as part of their own bespoke software.

The literature survey highlighted several issues with previous research such as assumed knowledge and over representation of values in the search space.
Throughout the design and implementation of the toolkit these issues were addressed where possible.
The toolkit was implemented so that irrespective of the system size each qubit is equally represent in the search.

Viewed as a software engineering project the success is quite evident with a fully implemented toolkit developed on time that meets all the requirements and provides a high level of functionality much greater than envisaged initially.
The software engineering process was rigorous and as a result the software produced is of a high standard.
Despite the continually increasing ambition throughout this project the fundamental design of the toolkit was largely unaltered from the start of development.
Where alterations were made they were not due to functional incompatibility with the original design but to improve the software engineering qualities such as modularity and reuse with the additional functionality.

Viewed as a research project the success is also evident from the results of the experiments carried out in Section \ref{sec:experimentation}.
These experiments were carried out in a manner that is reproducible and used only generic suitability measures provided with the toolkit.
As part of this experimentation the $0..3$ permutation experiment provided the inspiration for a suitability measure which is, to the best of my knowledge,  previously unseen in heuristic search, the Zero Focused suitability measure, see Section \ref{sec:simplsuitmeas}.
This suitability measure is now included as part of the toolkit and it is thought it will be useful for other quantum search problems beside the $0..3$ permutation experiment.
Additionally, several of the results presented are, to the best of my knowledge, unprecedented for heuristic search.
Not only are the individual results unprecedented but the collection of results produced using the same software is, to the best of my knowledge, unprecedented.
The different experiments may have used different suitability measures but they were all be specified, configured, run and analysed one after another all from within the same application.

The toolkit has been made freely available at \url{http://code.google.com/p/mengquantumalgorithm/}.
I hope it facilitates further research in the area of quantum algorithm synthesis via heuristic search.
